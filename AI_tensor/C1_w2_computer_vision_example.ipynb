{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f769f162",
   "metadata": {},
   "source": [
    "### Computer Vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f18016ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f1ad77",
   "metadata": {},
   "source": [
    "Load the Fashion MNIST dataset: is a collection of grayscale 28*28 pixel clothing images. Each image is associated with \n",
    "a label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3f5edde",
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOad the Fashion MNIST dataset\n",
    "fmist = tf.keras.datasets.fashion_mnist\n",
    "y= fmist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ffe27c9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0632d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the training and test split of the fashion mnist dataset\n",
    "(training_images, training_labels), (test_images, test_labels)= fmist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bac83e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of i :60000\n",
      "length of i :60000\n",
      "length of i :10000\n",
      "length of i :10000\n"
     ]
    }
   ],
   "source": [
    "x=[training_images, training_labels, test_images, test_labels]\n",
    "for i in x:\n",
    "    \n",
    "    print(f'length of i :{len(i)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b7b23d",
   "metadata": {},
   "source": [
    " What do these values look like??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ae7bdf83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the index is 0\n",
      "LABEL: 9\n",
      "\n",
      "IMAGE: PIXEL ARRAY:\n",
      " [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   1   0   0  13  73   0   0   1   4   0   0   0   0   1   1   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  36 136 127  62  54   0   0   0   1   3   4   0   0   3]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   6   0 102 204 176 134 144 123  23   0   0   0   0  12  10   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 155 236 207 178 107 156 161 109  64  23  77 130  72  15]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   1   0  69 207 223 218 216 216 163 127 121 122 146 141  88 172  66]\n",
      " [  0   0   0   0   0   0   0   0   0   1   1   1   0 200 232 232 233 229 223 223 215 213 164 127 123 196 229   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 183 225 216 223 228 235 227 224 222 224 221 223 245 173   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 193 228 218 213 198 180 212 210 211 213 223 220 243 202   0]\n",
      " [  0   0   0   0   0   0   0   0   0   1   3   0  12 219 220 212 218 192 169 227 208 218 224 212 226 197 209  52]\n",
      " [  0   0   0   0   0   0   0   0   0   0   6   0  99 244 222 220 218 203 198 221 215 213 222 220 245 119 167  56]\n",
      " [  0   0   0   0   0   0   0   0   0   4   0   0  55 236 228 230 228 240 232 213 218 223 234 217 217 209  92   0]\n",
      " [  0   0   1   4   6   7   2   0   0   0   0   0 237 226 217 223 222 219 222 221 216 223 229 215 218 255  77   0]\n",
      " [  0   3   0   0   0   0   0   0   0  62 145 204 228 207 213 221 218 208 211 218 224 223 219 215 224 244 159   0]\n",
      " [  0   0   0   0  18  44  82 107 189 228 220 222 217 226 200 205 211 230 224 234 176 188 250 248 233 238 215   0]\n",
      " [  0  57 187 208 224 221 224 208 204 214 208 209 200 159 245 193 206 223 255 255 221 234 221 211 220 232 246   0]\n",
      " [  3 202 228 224 221 211 211 214 205 205 205 220 240  80 150 255 229 221 188 154 191 210 204 209 222 228 225   0]\n",
      " [ 98 233 198 210 222 229 229 234 249 220 194 215 217 241  65  73 106 117 168 219 221 215 217 223 223 224 229  29]\n",
      " [ 75 204 212 204 193 205 211 225 216 185 197 206 198 213 240 195 227 245 239 223 218 212 209 222 220 221 230  67]\n",
      " [ 48 203 183 194 213 197 185 190 194 192 202 214 219 221 220 236 225 216 199 206 186 181 177 172 181 205 206 115]\n",
      " [  0 122 219 193 179 171 183 196 204 210 213 207 211 210 200 196 194 191 195 191 198 192 176 156 167 177 210  92]\n",
      " [  0   0  74 189 212 191 175 172 175 181 185 188 189 188 193 198 204 209 210 210 211 188 188 194 192 216 170   0]\n",
      " [  2   0   0   0  66 200 222 237 239 242 246 243 244 221 220 193 191 179 182 182 181 176 166 168  99  58   0   0]\n",
      " [  0   0   0   0   0   0   0  40  61  44  72  41  35   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
      "the index is 2\n",
      "LABEL: 0\n",
      "\n",
      "IMAGE: PIXEL ARRAY:\n",
      " [[  0   0   0   0   0   0   0   0   0  22 118  24   0   0   0   0   0  48  88   5   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  12 100 212 205 185 179 173 186 193 221 142  85   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  85  76 199 225 248 255 238 226 157  68  80   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  91  69  91 201 218 225 209 158  61  93  72   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  79  89  61  59  87 108  75  56  76  97  73   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  75  89  80  80  67  63  73  83  80  96  72   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  77  88  77  80  83  83  83  83  81  95  76   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  89  96  80  83  81  84  85  85  85  97  84   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  93  97  81  85  84  85  87  88  84  99  87   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  95  87  84  87  88  85  87  87  84  92  87   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  97  87  87  85  88  87  87  87  88  85 107   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  17 100  88  87  87  88  87  87  85  89  77 118   8   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  10  93  87  87  87  87  87  88  87  89  80 103   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   9  96  87  87  87  87  87  88  87  88  87 103   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  12  96  85  87  87  87  85  87  87  88  89 100   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  20  95  84  88  85  87  88  88  88  89  88  99   8   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  21  96  85  87  85  88  88  88  88  89  89  99  10   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  24  96  85  87  85  87  88  88  89  88  91 102  14   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  25  93  84  88  87  87  87  87  87  89  91 103  29   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  30  95  85  88  88  87  87  87  87  89  88 102  37   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  34  96  88  87  87  87  87  87  87  85  85  97  38   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  40  96  87  85  87  87  87  87  87  85  84  92  49   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  46  95  83  84  87  87  87  87  87  87  84  87  84   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  72  95  85  84  85  88  87  87  89  87  85  83  63   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  64 100  84  87  88  85  88  88  84  87  83  95  53   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  10 102 100  91  91  89  85  84  84  87 108 106  14   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   8  73  93 104 107 103 103 106 102  75  10   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   1   0   0   0  18  42  57  56  32   8   0   0   1   0   0   0   0   0   0   0]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "index=[0,2]\n",
    "np.set_printoptions(linewidth=320)\n",
    "for i in index:\n",
    "    print(f'the index is {i}')\n",
    "    print(f'LABEL: {training_labels[i]}')\n",
    "    print(f'\\nIMAGE: PIXEL ARRAY:\\n {training_images[i]}')\n",
    "\n",
    "    plt.imshow(training_images[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf484743",
   "metadata": {},
   "outputs": [],
   "source": [
    "## notice all the values are between 0 and 255, so scale the values between 0 and 1.\n",
    "\n",
    "# Normalize the pixel values of the training and test images\n",
    "training_images = training_images/255.0\n",
    "test_images = test_images/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc92d65c",
   "metadata": {},
   "source": [
    "### Build the classifiction model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2734fb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                   tf.keras.layers.Dense(128, activation= tf.nn.relu),\n",
    "                                   tf.keras.layers.Dense(10, activation =tf.nn.softmax)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24dce98f",
   "metadata": {},
   "source": [
    " Sequential: define the sequence of layers \n",
    "flatten = our image is 28 * 28 matrix, flatten convert it into one dimensionsl array\n",
    "dense = add layers of neurons\n",
    "Each layer of neurons need an activation function to tell them what to do. There are lot of options. But\n",
    "ReLu : if x>0:\n",
    "        return x\n",
    "       else:\n",
    "            return 0\n",
    "it means, it only passes the value grater than 0 to the next layer\n",
    "softmax : takes a list of values and scales these so that the sum of all elements will be equal to 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c993be96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input to softmax function: [[1. 3. 4. 2.]]\n"
     ]
    }
   ],
   "source": [
    "# Declare sample inputs and convert to a tensor\n",
    "inputs = np.array([[1.0, 3.0, 4.0, 2.0]])\n",
    "inputs = tf.convert_to_tensor(inputs)\n",
    "print (f'input to softmax function: {inputs.numpy()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "652f84a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output of softmax function : [[0.0320586  0.23688282 0.64391426 0.08714432]]\n"
     ]
    }
   ],
   "source": [
    "## feed the inputs to the softmax activation functio\n",
    "outputs = tf.keras.activations.softmax(inputs)\n",
    "print(f'output of softmax function : {outputs.numpy()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "301c6152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum of outputs: 1.0\n"
     ]
    }
   ],
   "source": [
    "# get the sum of all the values after the softmax\n",
    "sum = tf.reduce_sum(outputs)\n",
    "print(f'sum of outputs: {sum}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c82e65b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the class with highest probability : 2\n"
     ]
    }
   ],
   "source": [
    "## get the index with highest value\n",
    "prediction = np.argmax(outputs)\n",
    "print(f'the class with highest probability : {prediction}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0275927c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4980 - accuracy: 0.8248\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3761 - accuracy: 0.8641\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3361 - accuracy: 0.8779\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3139 - accuracy: 0.8832\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2953 - accuracy: 0.8916\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17bd731cb20>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=tf.optimizers.Adam(),\n",
    "             loss = 'sparse_categorical_crossentropy',\n",
    "             metrics = ['accuracy'])\n",
    "model.fit(training_images,training_labels,epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5c8964f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 824us/step - loss: 0.3572 - accuracy: 0.8738\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3572034537792206, 0.8737999796867371]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## evaluate the model\n",
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "43a29daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 712us/step\n"
     ]
    }
   ],
   "source": [
    "classifications =model.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "241019b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.2124478e-06 2.3055108e-08 2.8850113e-07 3.2583733e-07 6.7807696e-07 3.9944309e-03 3.7647328e-06 9.2553450e-03 1.1938173e-05 9.8672801e-01]\n"
     ]
    }
   ],
   "source": [
    "print(classifications[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f8eb0175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e95afb44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(classifications[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d07561",
   "metadata": {},
   "source": [
    " # Using Callbacks to control Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9dac26",
   "metadata": {},
   "source": [
    " We use callbacks api to stop training when specified metric is met. This is useful feature so we don't need \n",
    "    to complete all epochs when threshold is rached. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5875c88",
   "metadata": {},
   "source": [
    "#### Creating a callback class\n",
    "We can create a callback by defining a class that inherits the tf.keras.callbacks.Callback base class. From there we can define available\n",
    "methods to set where the call back will be executed ( example of method = on_epoch_end() to check the loss at each training epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9544453e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        '''\n",
    "        Halts the training after reaching 60 percent accuracy\n",
    "        Args:\n",
    "        epoch(integer)-index of epoch (required but not used in the function definition below)\n",
    "        logs (dict)-metric result from the training epoch\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        #check accuracy\n",
    "#         if(logs.get('accuracy')>0.85 ):\n",
    "#             #stop if threshold is met\n",
    "#             #print('\\nLoss is lower than 0.4 so cancelling training!')\n",
    "#             print('\\naccuracy threshold is reached so cancelling training!')\n",
    "#             self.model.stop_training =True\n",
    "        if((logs.get('accuracy')>0.95) | (logs.get('loss')<0.35)  ):\n",
    "            #stop if threshold is met\n",
    "            #print('\\nLoss is lower than 0.4 so cancelling training!')\n",
    "            print('\\n threshold is reached so cancelling training!')\n",
    "            self.model.stop_training =True\n",
    "# Instantiate class\n",
    "callbacks= myCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "71bb9d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and compile the model \n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape = (28,28)),\n",
    "    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "# compile\n",
    "model.compile(optimizer=tf.optimizers.Adam(),\n",
    "             loss =\"sparse_categorical_crossentropy\",\n",
    "             metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9f2b95dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.4721 - accuracy: 0.8324\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3569 - accuracy: 0.8689\n",
      "Epoch 3/10\n",
      "1866/1875 [============================>.] - ETA: 0s - loss: 0.3219 - accuracy: 0.8811\n",
      " threshold is reached so cancelling training!\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3220 - accuracy: 0.8810\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x221589fd850>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Train the model\n",
    "model.fit(training_images, training_labels, epochs=10, callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a5dbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### challenge modify the code to make the training stop when the accuracy metric exeeds 60%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5098d044",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
